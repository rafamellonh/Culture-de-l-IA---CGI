https://notebooklm.google.com/notebook/64843e90-a9f7-45db-abb8-0623cadfd16a?artifactId=2e8797e7-649a-4688-b3c9-401a9bb96ded

[![Ouvir √Åudio](https://img.shields.io/badge/üéß%20Ouvir%20√Åudio-4285F4?style=for-the-badge)](https://drive.google.com/file/d/1UBaZ4tfs-tEfnvFdL5P82B29J5g9YK0t/view?usp=sharing)


[![Assistir Aula](https://img.shields.io/badge/‚ñ∂Ô∏è%20Assistir%20Aula-4285F4?style=for-the-badge)](https://drive.google.com/file/d/1rusx8r-6XpZlpTGH9gTT1psh97mftrIl/view?usp=sharing)



# Fundamentos de IA e ML: M√©todos Fundamentais de Ci√™ncia de Dados

M√©todos de ci√™ncia de dados s√£o usados em v√°rios setores para gerar valor para os neg√≥cios. Machine Learning (ML, ou aprendizado de m√°quina) √© um m√©todo de ci√™ncia de dados que usa algoritmos de previs√£o para encontrar padr√µes em grandes quantidades de dados, permitindo que m√°quinas prevejam resultados futuros e tomem decis√µes com interven√ß√£o humana m√≠nima.

Este documento apresenta m√©todos fundamentais de uso de aprendizado de m√°quina.

Voc√™ vai ver o que √© machine learning, como ele √© categorizado e alguns casos de uso de aprendizado supervisionado e n√£o supervisionado. Depois, ver√° engenharia de atributos (feature engineering) e como isso impacta a performance do modelo. Em seguida, vamos focar em tipos comuns de tarefas de ML como clusteriza√ß√£o, classifica√ß√£o e regress√£o linear simples e m√∫ltipla. No final, voc√™ ver√° desafios comuns em ML e como lidar com eles.

Ap√≥s a leitura, voc√™ ser√° capaz de definir o que √© machine learning e descrever m√©todos para us√°-lo.

---

## √çndice

1. Vis√£o geral do curso  
2. Machine Learning (ML)  
3. Engenharia de atributos (Feature Engineering)  
4. Clusteriza√ß√£o  
5. Avalia√ß√£o da acur√°cia de algoritmos de clusteriza√ß√£o  
6. Classifica√ß√£o  
7. Avalia√ß√£o da acur√°cia de modelos de classifica√ß√£o  
8. Regress√£o  
9. Regress√£o linear simples  
10. Regress√£o linear m√∫ltipla  
11. Desafios em Machine Learning  
12. Resumo do curso  

---

## 1. Vis√£o geral do curso

Nesta parte:
- M√©todos comuns de ci√™ncia de dados  
- Casos de uso desses m√©todos  
- Como avaliar a performance  
- O que √© machine learning (ML)  
- Tarefas centrais de ML: clusteriza√ß√£o, classifica√ß√£o, regress√£o e engenharia de atributos  

M√©todos de ci√™ncia de dados s√£o usados em diferentes ind√∫strias para gerar valor. Este conte√∫do apresenta esses m√©todos e como avali√°-los.

---

## 2. Machine Learning (ML)

Nesta parte, voc√™ vai:
- Identificar casos de uso de machine learning  
- Diferenciar aprendizado supervisionado e n√£o supervisionado  

Machine learning √© um tipo de intelig√™ncia artificial (IA) que usa algoritmos para encontrar padr√µes em grandes quantidades de dados e prever resultados futuros com m√≠nima interven√ß√£o humana.

Os algoritmos de ML usam dados hist√≥ricos para fazer previs√µes. A maior parte de ML √© classificada como **aprendizado supervisionado** ou **aprendizado n√£o supervisionado**.

### Casos de uso reais de ML

Machine learning est√° por tr√°s de muitos servi√ßos do dia a dia:

- Sistemas de recomenda√ß√£o (streaming, e-commerce)
- Recomenda√ß√µes de produtos em lojas online
- Motores de busca
- Organiza√ß√£o do feed em redes sociais
- Assistentes de voz

Outros exemplos:
- Transporte e log√≠stica: manuten√ß√£o preditiva  
- Sa√∫de: identificar grupos de pacientes para tratamento personalizado usando t√©cnicas como processamento de linguagem natural  
- Finan√ßas: detec√ß√£o de fraude usando an√°lise de padr√µes  
- Vendas e marketing: prever churn (clientes que v√£o sair) e valor de vida do cliente (lifetime value)

### Aprendizado supervisionado

Aprendizado supervisionado treina m√°quinas usando dados rotulados para que elas possam fazer previs√µes sobre novos dados desconhecidos.

- Voc√™ tem vari√°veis de entrada (X) e uma vari√°vel de sa√≠da (Y)  
- Voc√™ treina um algoritmo para aprender a fun√ß√£o que liga X a Y  
- Objetivo: dado um novo X, prever Y  

"Dado rotulado" significa que cada exemplo vem com a resposta correta (por exemplo, "spam" ou "n√£o spam").

Exemplos de tarefas de aprendizado supervisionado:
- Classifica√ß√£o (classifica√ß√£o de imagens, filtro de spam, detec√ß√£o de fraude)
- Regress√£o (previs√£o de clima, previs√£o de PIB, previs√£o de mercado financeiro)
- Processamento de linguagem natural (reconhecimento de fala, an√°lise de sentimento, chatbots, tradu√ß√£o)
- Sistemas de recomenda√ß√£o
- Deep learning (gera√ß√£o de texto, detec√ß√£o de objetos, reconhecimento facial)

Exemplo:
- Um classificador de e-mail aprende quais mensagens s√£o spam comparando os atributos delas com e-mails que um humano j√° marcou como spam.

Outros exemplos:
- Diagn√≥stico m√©dico a partir de imagens
- Marca√ß√£o autom√°tica de fotos
- Reconhecimento de pedestres em carros aut√¥nomos

### Aprendizado n√£o supervisionado

Aprendizado n√£o supervisionado treina m√°quinas usando dados **sem r√≥tulo**, tentando descobrir estrutura ou padr√µes.  
N√£o existem categorias pr√©-definidas nem respostas corretas fornecidas.

Objetivos:
- Encontrar padr√µes
- Agrupar itens parecidos
- Entender a estrutura escondida nos dados

Analogia:
- Voc√™ d√° para uma crian√ßa uma tigela com bananas e laranjas e pede para separar.
- Mesmo sem saber as palavras "banana" e "laranja", ela consegue separar por tamanho, cor e forma.
- O aprendizado n√£o supervisionado faz algo parecido.

M√©todos comuns de aprendizado n√£o supervisionado:
- Clusteriza√ß√£o: agrupar pontos de dados parecidos, mesmo sem saber antes quais grupos existem
- Redu√ß√£o de dimensionalidade: reduzir o n√∫mero de vari√°veis para simplificar dados complexos
- Modelagem de t√≥picos (topic modeling): descobrir temas em muitos textos
- Detec√ß√£o de anomalias: achar comportamentos fora do padr√£o

Casos de uso:
- Segmenta√ß√£o de clientes no varejo
- Detec√ß√£o de fraude no banco analisando padr√µes incomuns
- Recomenda√ß√£o de conte√∫do em streaming
- Controle de qualidade na ind√∫stria (achar defeitos em linha de produ√ß√£o)

### Supervisionado vs. n√£o supervisionado

Diferen√ßas principais:

Aprendizado supervisionado:
- Faz previs√µes ou classifica√ß√µes com base em exemplos rotulados do passado  
- Precisa de dados rotulados  
- Risco: overfitting (o modelo "decorar" o treino e n√£o generalizar)  

Aprendizado n√£o supervisionado:
- Descobre padr√µes, estruturas e rela√ß√µes  
- Funciona com dados sem r√≥tulo  
- Desafio: interpretar os resultados pode ser dif√≠cil e depende do algoritmo  

---

## 3. Engenharia de atributos (Feature Engineering)

Nesta parte, voc√™ vai:
- Entender o processo de engenharia de atributos
- Entender o impacto disso na performance do modelo

Engenharia de atributos √© o processo de criar, transformar e selecionar os atributos (features) mais √∫teis para melhorar a performance do modelo.  
Isso vale tanto para aprendizado supervisionado quanto n√£o supervisionado.

Ela usa conhecimento do dom√≠nio para transformar dados brutos em sinais que um modelo consegue entender.

Por que isso √© importante:
- Melhora a precis√£o do modelo
- Torna as previs√µes mais interpret√°veis
- Reduz ru√≠do e complexidade

Exemplo:
- Voc√™ tem 30 atributos, mas talvez s√≥ "altura" realmente ajude a prever "peso".  
- Engenharia de atributos ajuda a descobrir quais atributos realmente importam.

Na √°rea da sa√∫de, combinar dados do paciente + exames + hist√≥rico pode gerar previs√µes mais precisas de risco de doen√ßas.

### T√©cnicas principais

1. **Cria√ß√£o de atributos (feature creation)**  
   - Criar novos atributos usando conhecimento do neg√≥cio ou padr√µes observados  
   - Pode melhorar performance, reduzir impacto de outliers e aumentar interpretabilidade  

2. **Transforma√ß√£o de atributos (feature transformation)**  
   - Converter atributos em representa√ß√µes mais √∫teis  
   - Ajuda efici√™ncia computacional  
   - Ajuda o modelo a capturar padr√µes mais profundos  
   - Exemplos: normaliza√ß√£o, codifica√ß√£o de categorias, log/square root/reciprocal transform  

3. **Escalonamento de atributos (feature scaling)**  
   - Colocar atributos em escalas parecidas, para que um atributo com valores muito grandes n√£o domine os outros  
   - Exemplos: min-max scaling, padroniza√ß√£o (standard scaling), robust scaling  

4. **Sele√ß√£o de atributos (feature selection)**  
   - Escolher s√≥ os atributos mais relevantes  
   - Reduz overfitting  
   - Melhora interpreta√ß√£o  
   - Reduz custo de processamento  
   - M√©todos:
     - M√©todos filtro (correla√ß√£o estat√≠stica)
     - M√©todos wrapper (testar subconjuntos)
     - M√©todos embutidos (o pr√≥prio modelo escolhe, como regulariza√ß√£o)

5. **Extra√ß√£o de atributos (feature extraction)**  
   - Combinar ou agregar atributos para gerar novos atributos mais informativos  
   - Normalmente reduz dimensionalidade  
   - Exemplos: redu√ß√£o de dimensionalidade, combina√ß√£o de atributos, agrega√ß√µes, PCA (An√°lise de Componentes Principais)

### Ferramentas comuns

- Em R: dplyr, tidyr, caret  
- Em Python: pandas, NumPy, scikit-learn, featuretools  

---

## 4. Clusteriza√ß√£o

Nesta parte, voc√™ vai:
- Entender o que √© clusteriza√ß√£o  
- Ver benef√≠cios e desafios  

Clusteriza√ß√£o √© um exemplo de aprendizado n√£o supervisionado.

Voc√™ trabalha com dados sem r√≥tulo e tenta descobrir estrutura (grupos de pontos parecidos). Esses grupos s√£o chamados de clusters.

Objetivo:
- Encontrar similaridade entre pontos de dados  
- Agrupar de forma significativa  
- Revelar segmentos naturais  

### Vantagens da clusteriza√ß√£o

- Descobre padr√µes escondidos  
- Ajuda na visualiza√ß√£o: mostra quais pontos "pertencem" juntos  
- Funciona mesmo quando r√≥tulos seriam caros ou imposs√≠veis de obter  
- Pode funcionar com dados de v√°rios tipos (num√©ricos, categ√≥ricos), dependendo do algoritmo  

### Limita√ß√µes e desafios

- Muitas vezes voc√™ precisa de etapas extras para validar se os grupos fazem sentido de verdade  
- Alguns algoritmos assumem formato ou tamanho espec√≠fico dos clusters  
- Alguns n√£o escalam bem quando h√° muitas vari√°veis (alta dimensionalidade)  
- Alguns n√£o lidam bem com clusters de tamanhos muito diferentes  
- Misturar dados categ√≥ricos e num√©ricos pode ser problema dependendo do algoritmo  

### Para que usar clusteriza√ß√£o?

Clusteriza√ß√£o responde perguntas de similaridade, como:
- "Com qual grupo este cliente parece mais?"
- "Quais comportamentos aparecem juntos com frequ√™ncia?"

Exemplos de uso:
- Agrupar e-mails/textos de clientes para medir satisfa√ß√£o  
- Monitorar a propaga√ß√£o de doen√ßas  
- Encontrar padr√µes de compra no hist√≥rico de transa√ß√µes  
- Criar segmentos de marketing para campanhas direcionadas  

Importante:
- Clusteriza√ß√£o pode gerar grupos que n√£o s√£o √≥bvios.
- Voc√™ ainda precisa interpretar e explicar o que cada grupo significa para o neg√≥cio.

### Exemplo do mundo real

Em 1997, um estudo sobre limite de cr√©dito usou clusteriza√ß√£o para separar clientes de cart√£o de cr√©dito em cinco grupos.  
Entradas analisadas:
- Quanto pegavam emprestado  
- Frequ√™ncia de atraso no pagamento  
- H√°bitos de gasto  

Objetivo: prever o comportamento do cliente e ajustar marketing de forma mais eficiente.

---

## 5. Avalia√ß√£o da acur√°cia de algoritmos de clusteriza√ß√£o

Nesta parte, voc√™ vai:
- Ver como avaliar a qualidade de uma clusteriza√ß√£o

Objetivo da clusteriza√ß√£o:
- Maximizar a separa√ß√£o entre clusters (clusters bem separados)
- Minimizar a dist√¢ncia dentro de cada cluster (itens do mesmo cluster muito parecidos)

Conceitos √∫teis:
- Dist√¢ncia ou vari√¢ncia entre clusters: qu√£o longe os clusters est√£o uns dos outros  
- Dist√¢ncia dentro do cluster: qu√£o pr√≥ximos est√£o os pontos dentro do mesmo grupo  

Uma forma de medir:
- Calcular a raz√£o entre a vari√¢ncia entre clusters e a vari√¢ncia total  
- Quanto maior a separa√ß√£o, mais "forte" pode ser a clusteriza√ß√£o  
- O c√°lculo exato depende do algoritmo

Outra ferramenta √∫til: gr√°fico "scree"
- Mostra quanta vari√¢ncia cada componente explica  
- Ajuda a enxergar quais dimens√µes (atributos) mais importam

### Perguntas que voc√™ deve fazer como gestor

- Como a dist√¢ncia foi medida? (por exemplo, dist√¢ncia Euclidiana, Manhattan etc.)  
- Os dados foram escalonados corretamente?  
  - Exemplo: se um atributo varia de 1 a 100 e outro de 0 a 1, isso pode distorcer o agrupamento sem normaliza√ß√£o  
- Quantos clusters eram esperados?  
  - Se voc√™ queria 4 segmentos de marketing e recebeu 20 clusters, isso ainda √© √∫til?  
- O algoritmo escala bem no volume de dados que voc√™ tem?  
  - Ele consegue rodar quase em tempo real conforme os dados crescem?  
- √â poss√≠vel interpretar os grupos resultantes?  
  - Se voc√™ n√£o consegue explicar o que cada grupo significa, talvez o resultado n√£o seja acion√°vel

### Armadilhas e impactos

- N√£o existem r√≥tulos, ent√£o n√£o d√° pra dizer "certo" ou "errado" como na classifica√ß√£o supervisionada  
- √â preciso interpretar os clusters  
- Pode ser necess√°rio usar m√©todos adicionais para confirmar se os padr√µes s√£o reais

"Maldi√ß√£o da dimensionalidade":
- Quando voc√™ tem muitos atributos (muitas colunas):
  - Os dados ficam esparsos  
  - Dist√¢ncias deixam de ser t√£o significativas  
  - Fica mais dif√≠cil separar grupos de forma clara  

Alguns algoritmos:
- Sofrem com mistura de dados categ√≥ricos e num√©ricos  
- Assumem formatos espec√≠ficos dos clusters  
- N√£o escalam bem quando o n√∫mero de atributos cresce muito  

### Quando usar clusteriza√ß√£o

Use clusteriza√ß√£o quando:
1. Voc√™ tem dados sem r√≥tulo  
2. Os dados t√™m v√°rios atributos  
3. Voc√™ quer identificar padr√µes ou grupos naturais  
4. Voc√™ quer descobrir estruturas escondidas que n√£o aparecem em gr√°ficos simples  

---

## 6. Classifica√ß√£o

Nesta parte, voc√™ vai:
- Ver usos de classifica√ß√£o  
- Conhecer classificadores comuns  

Classifica√ß√£o √© um tipo de aprendizado supervisionado.

Ela atribui novos exemplos (novos dados) a classes conhecidas com base em semelhan√ßa com dados rotulados usados no treino.

O modelo:
- Aprende uma rela√ß√£o entre entrada e sa√≠da usando dados rotulados  
- Usa essa rela√ß√£o para classificar novos dados

### Benef√≠cios

- Ajuda a medir similaridade entre ideias, eventos, objetos ou pessoas  
- Organiza dados em r√≥tulos claros  
- Suporta v√°rias √°reas (detec√ß√£o de fraude, triagem m√©dica etc.)  

### Desafios

- Pode sofrer overfitting: aprender ru√≠do do treino e errar em dados novos  
- Precisa de dados rotulados, que s√£o caros e demorados para produzir  
- O treino pode consumir bastante tempo e recurso computacional  

### Usos pr√°ticos

- Prever probabilidades (ex.: "70% de chance de ser spam" ‚Üí ent√£o marcar como spam)  
- Prever pertencimento a um grupo  
- Dizer se um objeto ou pessoa √© semelhante a outro padr√£o conhecido  

### Exemplo real

Um grande varejista analisou padr√µes de compra para prever quais clientes provavelmente estavam gr√°vidos e ent√£o enviou cupons direcionados.  
Isso gerou preocupa√ß√µes √©ticas e de privacidade porque previu informa√ß√µes sens√≠veis de sa√∫de sem comunica√ß√£o expl√≠cita.

### Classificadores comuns

- **Regress√£o log√≠stica**  
  - Retorna probabilidades  
  - F√°cil de interpretar  
  - Muito usada em finan√ßas e sa√∫de  

- **SVM (Support Vector Machine / M√°quina de Vetor de Suporte)**  
  - Funciona bem quando as classes s√£o separ√°veis  
  - Encontra a fronteira de decis√£o √≥tima  

- **√Årvores de decis√£o**  
  - Tomam decis√µes seguindo regras do tipo "se ... ent√£o ..."  
  - F√°ceis de explicar para √°reas de neg√≥cio  
  - Base de modelos em conjunto como Random Forest e XGBoost  

- **k-vizinhos mais pr√≥ximos (k-NN)**  
  - Baseado em dist√¢ncia  
  - Assume que itens parecidos ficam "perto" uns dos outros  
  - Classifica um ponto com base nas classes dos vizinhos mais pr√≥ximos  

---

## 7. Avalia√ß√£o da acur√°cia de modelos de classifica√ß√£o

Nesta parte, voc√™ vai:
- Ver fatores que afetam a acur√°cia de um modelo de classifica√ß√£o

Para avaliar um modelo de classifica√ß√£o:

1. Dividir os dados em:
   - Conjunto de treino (o modelo aprende aqui)
   - Conjunto de teste (o modelo √© avaliado aqui)

2. Comparar previs√µes com resultados reais usando uma matriz de confus√£o.

### Termos da matriz de confus√£o

- Verdadeiro Positivo (VP / TP): previsto positivo e era positivo  
- Verdadeiro Negativo (VN / TN): previsto negativo e era negativo  
- Falso Positivo (FP): previsto positivo mas era negativo  
- Falso Negativo (FN): previsto negativo mas era positivo  

Tamb√©m se analisa performance usando a curva ROC (Receiver Operating Characteristic):

- Mostra a taxa de verdadeiros positivos vs. taxa de falsos positivos em v√°rios limiares de probabilidade  
- Cada limiar gera uma matriz de confus√£o diferente  

AUC (√Årea sob a Curva ROC):
- Mede a capacidade geral do modelo de separar classes  
- AUC maior que 0,5 significa "melhor que chute aleat√≥rio"  

### Perguntas que voc√™ deve fazer como gestor

- Como foi escolhida a m√©trica de dist√¢ncia (se aplic√°vel)?  
- Como os dados foram divididos entre treino e teste?  
- Os dados foram normalizados/escalonados?  
- Quais limiares (thresholds) foram usados para calcular ROC e AUC?  

### Quando usar classifica√ß√£o

Use classifica√ß√£o quando:
- Voc√™ tem dados rotulados  
- Voc√™ quer prever a qual grupo algo pertence  
- Voc√™ quer prever comportamentos ou eventos futuros  
- Voc√™ quer entender quais vari√°veis est√£o influenciando a decis√£o  

---

## 8. Regress√£o

Nesta parte, voc√™ vai:
- Entender o que √© regress√£o  
- Ver benef√≠cios e desafios  

Regress√£o cria uma linha de melhor ajuste para um conjunto de dados e prev√™ o valor de uma vari√°vel com base em outra.

Ela analisa rela√ß√µes entre vari√°veis.

Diferen√ßa para classifica√ß√£o:
- Regress√£o prev√™ valores num√©ricos cont√≠nuos  
- Classifica√ß√£o prev√™ categorias (classes)

### Benef√≠cios e desafios

Benef√≠cios:
- Pode fornecer uma forma objetiva de prever eventos  
- Ajuda a priorizar quais fatores mais influenciam o resultado  
- Ajuda a guiar quais dados devem ser coletados  

Desafios:
- Dados faltantes podem atrasar an√°lise  
- Construir e manter modelos pode ser caro  
- Exige conhecimento do dom√≠nio para interpretar corretamente  
- Alta variabilidade ou problema mal definido pode gerar incerteza sobre qual abordagem de modelagem usar  

### Perguntas que a regress√£o pode responder

- Quais fatores importam mais?  
- Quais fatores podem ser ignorados?  
- Existe intera√ß√£o entre fatores?  
- Qu√£o confiantes estamos nessas conclus√µes?  

---

## 9. Regress√£o linear simples

Nesta parte, voc√™ vai:
- Ver casos de uso de regress√£o linear simples

T√≥picos:
- Regress√£o linear simples  
- Medi√ß√£o de erro  
- Tratamento de outliers  
- Medindo acur√°cia  
- M√©tricas comuns de avalia√ß√£o em regress√£o  

Regress√£o linear simples √© muitas vezes o primeiro modelo que cientistas de dados aprendem.

Objetivo:
- Encontrar a linha que melhor se ajusta aos dados  
- Minimizar a dist√¢ncia entre essa linha e cada observa√ß√£o  
- Usar essa linha para prever resultados com base em um √∫nico preditor  

Passos b√°sicos:
1. Coletar os dados  
2. Plotar os dados para ver se h√° um padr√£o aproximadamente linear  
3. Ajustar a linha de melhor ajuste  

### Medindo erro

Jeitos de medir erro:
- Vari√¢ncia: qu√£o distantes os valores reais est√£o dos valores esperados  
- Aleatoriedade: os erros s√£o aleat√≥rios ou existe vi√©s?  
- Desvio padr√£o / certeza: qu√£o concentrados os valores est√£o em torno da previs√£o esperada  

### Outliers

Outliers (valores muito fora do padr√£o) podem distorcer muito a inclina√ß√£o (slope) e o intercepto da linha de regress√£o.

Ferramentas para detectar outliers:
- Gr√°fico de dispers√£o (scatterplot)  
- Boxplot (box-and-whisker)  
- Dist√¢ncia de Cook (Cook‚Äôs distance)  

### M√©tricas de acur√°cia

- Covari√¢ncia: como duas vari√°veis variam juntas  
- Correla√ß√£o: vers√£o normalizada da covari√¢ncia, vai de -1 a +1  
- Valor-p (p-value): qu√£o prov√°vel seria observar essa rela√ß√£o se, na verdade, n√£o existisse rela√ß√£o linear na popula√ß√£o  
- R-quadrado (R¬≤): porcentagem da varia√ß√£o nos dados explicada pelo modelo  

Duas m√©tricas comuns de erro:

- RMSE (Root Mean Squared Error / Raiz do Erro Quadr√°tico M√©dio)  
  - Usa os res√≠duos (erros) ao quadrado  
  - Quanto menor, melhor  

- MAE (Mean Absolute Error / Erro M√©dio Absoluto)  
  - M√©dia do valor absoluto da diferen√ßa entre previsto e real  
  - Aumenta conforme os erros aumentam  

---

## 10. Regress√£o linear m√∫ltipla

Nesta parte, voc√™ vai:
- Entender como usar regress√£o linear m√∫ltipla

Regress√£o linear m√∫ltipla estende a regress√£o linear simples para incluir mais de uma vari√°vel independente (mais de um preditor).

Objetivo:
- Entender como v√°rios preditores, juntos, afetam a vari√°vel alvo

### Problemas adicionais em regress√£o m√∫ltipla

- Multicolinearidade:  
  - Dois ou mais preditores s√£o altamente correlacionados entre si  
  - Voc√™ pode "contar duas vezes" o mesmo efeito sem perceber  

- Autocorrela√ß√£o:  
  - Os erros (res√≠duos) n√£o s√£o independentes  
  - A observa√ß√£o atual est√° relacionada com observa√ß√µes anteriores  

- Heterocedasticidade:  
  - A vari√¢ncia dos erros n√£o √© constante  
  - Ou seja, o quanto o modelo erra depende do n√≠vel do preditor  

### Perguntas que voc√™ deve fazer como gestor

- N√≥s entendemos a distribui√ß√£o dos dados?  
- Outliers foram identificados? Eles eram importantes? Foram removidos?  
- As vari√°veis foram testadas para multicolinearidade (para n√£o contar o mesmo efeito duas vezes)?  
- Qual foi o R-quadrado (R¬≤)?  

---

## 11. Desafios em Machine Learning

Nesta parte, voc√™ vai:
- Ver desafios comuns em ML

Desafios comuns:

1. Poucos dados de treino  
   - Leva a overfitting  
   - O modelo aprende ru√≠do em vez de padr√£o real  
   - Alta vari√¢ncia: vai muito bem no treino e mal em dados novos  
   - Poss√≠veis solu√ß√µes:
     - Coletar mais dados  
     - Gerar dados sint√©ticos (por exemplo, t√©cnicas de oversampling)  

2. Dados de treino n√£o representativos  
   - Voc√™ treina com um subconjunto limitado da popula√ß√£o  
   - Se esse subconjunto √© pequeno ou enviesado, o modelo n√£o generaliza  
   - Isso cria vi√©s de amostragem  
   - O objetivo √© equilibrar vi√©s e vari√¢ncia (trade-off vi√©s/vari√¢ncia)  

3. Qualidade ruim dos dados  
   - Valores ausentes  
   - Erros  
   - Ru√≠do  
   - Duplicados  
   - Registros incompletos  
   - Solu√ß√µes:
     - Limpeza de dados  
     - Remo√ß√£o ou tratamento de outliers  
     - Deduplica√ß√£o  
     - Tratamento de valores ausentes  

4. Atributos irrelevantes  
   - "Lixo entra, lixo sai"  
   - Se voc√™ fornece atributos irrelevantes, voc√™ recebe previs√µes ruins  
   - Solu√ß√µes:
     - Engenharia de atributos  
     - Sele√ß√£o de atributos:
       - Manter s√≥ os atributos relevantes  
       - T√©cnicas:
         - Regulariza√ß√£o (Ridge, Lasso)  
         - Import√¢ncia de atributos em Random Forests  
         - Sele√ß√£o estat√≠stica  
     - Extra√ß√£o de atributos:
       - Criar novos atributos a partir de conhecimento do dom√≠nio  
       - Redu√ß√£o de dimensionalidade (por exemplo, PCA)  
       - Combina√ß√£o / agrega√ß√£o de atributos para gerar sinais mais fortes  

---

## 12. Resumo do curso

Neste conte√∫do:
- Voc√™ definiu o que √© machine learning e onde ele √© usado  
- Voc√™ viu m√©todos fundamentais de ML:
  - Clusteriza√ß√£o  
  - Classifica√ß√£o  
  - Regress√£o  
- Voc√™ aprendeu como avaliar a performance de modelos  
- Voc√™ revisou desafios comuns de ML e estrat√©gias para lidar com eles  

---

Copyright 2025 Skillsoft Ireland Limited. Todos os direitos reservados.



https://cdn2.percipio.com/secure/c/1761497995.80b76f0f861e0e1d28122c32a99255eff6b17ce9/eot/transcripts/a583c2bd-30b5-4797-be49-c85586632644/it_aidfamdj_01_enus.html
